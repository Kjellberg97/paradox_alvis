This job can be monitored from: https://scruffy.c3se.chalmers.se/d/alvis-job/alvis-job?var-jobid=842444&from=1677848246000
INFO:    underlay of /etc/localtime required more than 50 (94) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (470) bind mounts
INFO:    underlay of /usr/share/lmod/lmod required more than 50 (59) bind mounts
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
Loading data...
Formatting complete.

Map:   0%|          | 0/2 [00:00<?, ? examples/s]Map: 100%|██████████| 2/2 [00:00<00:00, 12.72 examples/s]                                                         Mapping complete.
Formatting complete.

Map:   0%|          | 0/2 [00:00<?, ? examples/s]                                                 Mapping complete.
Formatting complete.

Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  Mapping complete.
Converting to dictionary.
Data loading complete.
Running inference...
Inputs
Dataset({
    features: ['input', 'target', 'labels', 'input_ids', 'attention_mask'],
    num_rows: 10
})
<class 'torch.Tensor'>
tensor([[    0, 45152,   108,  ...,     1,     1,     1],
        [    0, 45152,   108,  ...,     1,     1,     1],
        [    0, 45152,   108,  ...,     1,     1,     1],
        ...,
        [    0, 45152,   108,  ...,   108,  7479,     2],
        [    0, 45152,   108,  ...,     1,     1,     1],
        [    0, 45152,   108,  ...,     1,     1,     1]])
torch.Size([10, 1024])
Generating output...
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:19<?, ?it/s]
[tensor([[    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
         23760, 49177,    22,   879, 46749, 42248, 13373, 25522,  3934, 23760,
         13373,   112, 46961, 48268,   128, 33480, 13373,   112, 24303,     2,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0,     0,     0, 45152,   108, 13319, 13373, 25522,   108,
         10975, 49329, 43146,   219, 49177,    22,   757, 45593, 42248, 13373,
         25522,  3934, 41833, 49329,  2611,  1342,  2088, 49177,    22, 43146,
           219, 42248, 13373, 47517,   108, 49329,  3479, 49177,    22,  2611,
          1342, 15589, 42248, 13373, 49153, 48268,   128, 33480, 13373,   321,
         24303,     2,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
         10724,   219,  1297,    22, 43198, 49177,    22,   642, 47229,  5580,
         42248, 13373, 25522,  3934, 10724,   219, 13373,   112,     6, 41833,
         49329,  5234, 22191,  1297,    22, 17165, 24115, 49177,    22, 43198,
         42248, 13373, 47517, 49329, 43198,  1297,    22, 10724,   219, 49177,
            22,  5234, 22191, 42248, 13373, 45152,   108, 43198, 13373,   321,
         49908, 48268,   128, 33480, 13373,   321, 24303,     2],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
          5234, 22191, 49177,    22,  8361,   352, 42248, 13373, 25522,  3934,
          5234, 22191, 13373,   112, 46961, 48268,   128, 33480, 13373,   112,
         24303,     2,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0,     0,     0, 45152,   108, 13319, 13373, 25522,   108,
          2544, 44611, 13373,   112, 48268,   128, 33480, 13373,   112, 24303,
             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
           242,  4308,   927, 49177,    22,    29, 31452, 42248, 13373, 25522,
          3934, 10975, 49329, 28878, 16170,  1297,    22, 20473,  1297,    22,
         37251, 49177,    22, 10975, 49329,   428,  3995, 49177,    22, 28878,
         16170, 42248, 13373, 45152,   108,   428,  3995, 13373,   112, 46961,
         48268,   128, 33480, 13373,   321, 24303,     2,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
            90,  9401, 49177,    22,  8396, 42248, 13373, 25522, 13373, 25522,
          3934,    90,  9401, 13373,   321, 24303, 48268,   128, 33480, 13373,
           321, 46961,     2,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
         13562, 24786, 49177,    22, 10999,    12, 17950, 25292, 42248, 13373,
         25522, 44403, 10975, 49329,  1193,   219,  1297,    22, 17165, 24115,
         49177,    22, 13562, 24786, 42248, 13373, 45152,   108,  1193,   219,
         13373,   112,     6,   128, 17165, 24115, 13373,   112, 46961, 48268,
           128, 33480, 13373,   112, 24303,     2,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108,   417,  1173,
         28180, 13373,   112, 48268,   128, 33480, 13373,   112, 24303,     2,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 45152,   108, 13319, 13373, 25522,   108, 10975, 49329,
         43146,   219,  1297,    22, 26086,  2650, 49177,    22, 26086,  1672,
         42248, 13373, 25522,  3934, 10975, 49329,  3697, 36931,  1297,    22,
          3998, 48357,  1297,    22, 13367,  1173, 49177,    22, 43146,   219,
         42248, 13373, 49189, 49329,   506, 23382, 49177,    22,  3697, 36931,
         42248, 13373, 47517,   108,   506, 23382, 13373,   112, 49908, 48268,
           128, 33480, 13373,   321, 24303,     2,     1,     1]])]
Decoding
[['{\'proof\': {\'[["loving"], "unpleasant"]\': {\',loving\': 1}}}, \'label\': 1}', '{\'proof\': {\'[["sleepy"], "impartial"]\': {\', \'[["attentive"], "sleepy"]\': {{\'["long"], "attentitive"]\': {}}, \'label\': 0}', '{\'proof\': {\'[["weary", "rational"], "pessimistic"]\': {\',weary\': 1, \'[["precious", "distinct"], "rational"]\': {{["rational", "weary"], "precious"]\':{\'rational\': 0}}}}, \'label\': 0}', '{\'proof\': {\'[["precious"], "homely"]\': {\',precious\': 1}}}, \'label\': 1}', "{'proof': {'intellectual': 1}, 'label': 1}", '{\'proof\': {\'[["elegant"], "sensible"]\': {\',[["beautiful", "perfect", "different"], "[["bored"], "beautiful"]\':{\'bored\': 1}}}, \'label\': 0}', '{\'proof\': {\'[["tense"], "good"]\': {\': {\',tense\': 0}}, \'label\': 0}}', '{\'proof\': {\'[["horrible"], "bad-tempered"]\': {\'][["shy", "distinct"], "horrible"]\':{\'shy\': 1, \'distinct\': 1}}}, \'label\': 1}', "{'proof': {'dishonest': 1}, 'label': 1}", '{\'proof\': {\'[["sleepy", "thoughtful"], "thoughtless"]\': {\',[["versatile", "clumsy", "selfish"], "sleepy"]\': {"["frail"], "versatile"]\': {{\'frail\': 1}}}}, \'label\': 0}']]
Saving output...
Saving to /cephyr/users/danens/Alvis/paradox_alvis/output/output.txt...
